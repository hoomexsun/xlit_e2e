{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ba662e14",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "c165af5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import Seq2Seq\n",
    "import torch\n",
    "from utils import load_yaml\n",
    "from tokenizers import load_tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ea3a8e",
   "metadata": {},
   "source": [
    "## 1. Load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "080f994c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenizer loaded from exp\\ben_char_tokenizer.yaml\n",
      "Tokenizer loaded from exp\\mni_char_tokenizer.yaml\n"
     ]
    }
   ],
   "source": [
    "token_type = \"char\"\n",
    "lang1 = \"ben\"\n",
    "lang2 = \"mni\"\n",
    "\n",
    "x_tokenizer = load_tokenizer(token_type, lang1)\n",
    "y_tokenizer = load_tokenizer(token_type, lang2)\n",
    "\n",
    "PARAMS_FILE = \"data/params.yaml\"\n",
    "params = load_yaml(PARAMS_FILE)\n",
    "EMBED_DIM = params[\"embed_dim\"]\n",
    "HIDDEN_DIM = params[\"hidden_dim\"]\n",
    "\n",
    "xlit_dict = load_yaml(\"conf/train.yaml\")\n",
    "model_name = xlit_dict[\"xlit\"]\n",
    "xlit_conf = xlit_dict[\"xlit_conf\"]\n",
    "ENCODER_LAYERS = xlit_conf[\"encoder_layers\"]\n",
    "DROPOUT_RATE = xlit_conf[\"dropout_rate\"]\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ce414eaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Seq2Seq(\n",
    "    input_dim=len(x_tokenizer.tok2idx),\n",
    "    output_dim=len(y_tokenizer.tok2idx),\n",
    "    embed_dim=EMBED_DIM,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    num_layers=ENCODER_LAYERS,\n",
    "    dropout=DROPOUT_RATE,\n",
    "    device=DEVICE\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2c8edba",
   "metadata": {},
   "source": [
    "## 2. Load checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "200d16fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "EXP_DIR = f\"exp/{model_name}_{token_type}_{lang1}_{lang2}\"\n",
    "checkpoint_file = f\"{EXP_DIR}/epoch_80.pth\"\n",
    "checkpoint = torch.load(checkpoint_file)\n",
    "\n",
    "model.load_state_dict(checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "724063a8",
   "metadata": {},
   "source": [
    "## 3. Enter text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "ceb041b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_text = \"রেফরি\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "907c311b",
   "metadata": {},
   "source": [
    "## 4. Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "0a1f1417",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ꯔꯦꯁꯔꯤ']\n"
     ]
    }
   ],
   "source": [
    "tokenized_text = x_tokenizer.encode(random_text, max_len=100)\n",
    "input_tensor = torch.tensor(tokenized_text).unsqueeze(0)\n",
    "\n",
    "\n",
    "with torch.no_grad():\n",
    "    outputs = model(x=input_tensor, y=None, max_len=100, sos_token=y_tokenizer.tok2idx[\"<sos>\"])\n",
    "\n",
    "predicted_ids = outputs.argmax(dim=2)\n",
    "decoded_preds = [y_tokenizer.decode(pred.tolist()) for pred in predicted_ids]\n",
    "\n",
    "print(decoded_preds)  # list of predicted strings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a944a8da",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
